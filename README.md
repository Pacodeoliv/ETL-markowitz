# ETL-markowitz: Otimiza√ß√£o de Portf√≥lio de Investimentos com Python e Azure

![Python](https://img.shields.io/badge/Python-3.10-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Azure](https://img.shields.io/badge/Azure-Data_Lake-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-1.50-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-2.3-150458?style=for-the-badge&logo=pandas&logoColor=white)

Este projeto √© um pipeline de dados completo (ETL/ELT) que extrai dados hist√≥ricos do mercado de a√ß√µes, calcula a aloca√ß√£o de portf√≥lio √≥tima com base na Teoria Moderna de Portf√≥lio de Markowitz e apresenta os resultados em um dashboard web interativo.

## üèõÔ∏è Arquitetura do Projeto

O fluxo de dados foi desenhado para ser modular e escal√°vel, utilizando servi√ßos da nuvem Azure para armazenamento e uma aplica√ß√£o local para orquestra√ß√£o, processamento e visualiza√ß√£o.

```mermaid
graph TD
    %% --- Defini√ß√£o de Estilos ---
    classDef azure fill:#dae8fc,stroke:#6c8ebf,stroke-width:2px;
    classDef local fill:#e2f0d9,stroke:#5a8a47,stroke-width:2px;
    classDef source fill:#f5f5f5,stroke:#666,stroke-width:2px;

    %% --- Defini√ß√£o dos Componentes ---
    subgraph "Fonte de Dados"
        API[<fa:fa-chart-line> API yfinance]:::source
    end

    subgraph "Aplica√ß√£o Local Python"
        Extractor[<fa:fa-download> extractor.py]:::local
        Transformer[<fa:fa-cogs> transformer.py]:::local
        Dashboard[<fa:fa-desktop> app.py]:::local
    end
    
    subgraph "Nuvem Azure"
        ADLS_Raw[<fa:fa-database> Azure Data Lake Zona Bruta]:::azure
        ADLS_Processed[<fa:fa-check-circle> Azure Data Lake Zona Processada]:::azure
    end

    %% --- Conex√µes e Fluxo de Dados ---
    API -- 1. Extrai dados --> Extractor
    Extractor -- 2. Carrega dados brutos --> ADLS_Raw
    ADLS_Raw -- 3. L√™ dados brutos --> Transformer
    Transformer -- 4. Processa e calcula portf√≥lio --> Transformer
    Transformer -- 5. Carrega resultados --> ADLS_Processed
    ADLS_Processed -- 6. L√™ resultados para visualiza√ß√£o --> Dashboard
```

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.10
* **Gerenciamento de Depend√™ncias:** Poetry
* **An√°lise de Dados:** Pandas, NumPy
* **Fonte de Dados:** yfinance API
* **Otimiza√ß√£o de Portf√≥lio:** PyPortfolioOpt
* **Armazenamento na Nuvem:** Azure Data Lake Storage Gen2
* **Dashboard Interativo:** Streamlit
* **Visualiza√ß√£o de Dados:** Plotly Express

## üìÇ Estrutura do Projeto

```
ETL-markowitz/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ etl_markowitz/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ extractor.py      # Script para Extrair (E) e Carregar (L) dados brutos
‚îÇ       ‚îî‚îÄ‚îÄ transformer.py    # Script para Transformar (T) os dados
‚îú‚îÄ‚îÄ .env                      # Arquivo local com as credenciais do Azure (n√£o versionado)
‚îú‚îÄ‚îÄ .gitignore                # Arquivos e pastas a serem ignorados pelo Git
‚îú‚îÄ‚îÄ app.py                    # Aplica√ß√£o principal do dashboard Streamlit
‚îú‚îÄ‚îÄ poetry.lock               # Arquivo de lock para depend√™ncias determin√≠sticas
‚îú‚îÄ‚îÄ pyproject.toml            # Arquivo de configura√ß√£o do projeto e depend√™ncias
‚îî‚îÄ‚îÄ README.md                 # Documenta√ß√£o do projeto
```

## üöÄ Como Executar o Projeto Localmente

**Pr√©-requisitos:**
* Python 3.10+
* Poetry instalado
* Uma conta no Microsoft Azure com um Data Lake Storage Gen2 configurado

**Passos:**

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/ETL-markowitz.git](https://github.com/seu-usuario/ETL-markowitz.git)
    cd ETL-markowitz
    ```

2.  **Instale as depend√™ncias:**
    ```bash
    poetry install
    ```

3.  **Configure suas credenciais:**
    * Crie um arquivo chamado `.env` na raiz do projeto.
    * Dentro dele, adicione a sua Connection String do Azure:
        ```env
        AZURE_STORAGE_CONNECTION_STRING="SuaConnectionstringCompletaAqui"
        ```

4.  **Execute o pipeline de ETL:**
    * Primeiro, execute o script de extra√ß√£o para buscar os dados da API e salv√°-los na Zona Bruta do Data Lake.
        ```bash
        poetry run python src/etl_markowitz/extractor.py
        ```
    * Em seguida, execute o script de transforma√ß√£o para ler os dados brutos, calcular o portf√≥lio e salvar os resultados na Zona Processada.
        ```bash
        poetry run python src/etl_markowitz/transformer.py
        ```

5.  **Inicie o Dashboard:**
    * Com os dados processados na nuvem, inicie a aplica√ß√£o Streamlit.
        ```bash
        poetry run streamlit run app.py
        ```
    * Seu navegador abrir√° automaticamente no endere√ßo do dashboard.

## üìä Resultado Final

O projeto resulta em um dashboard web interativo que apresenta a aloca√ß√£o de ativos recomendada para maximizar o retorno ajustado ao risco, juntamente com as m√©tricas de performance esperadas para este portf√≥lio.

![Image](https://github.com/user-attachments/assets/60e36b3b-f68a-4250-aadd-cdd911b57529)
